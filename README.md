ğŸ–¼ï¸ Dashboard Preview

<img width="1346" height="673" alt="image" src="https://github.com/user-attachments/assets/559098fa-69de-4b79-b019-acdb41b0ab30" />


(Insert your dashboard image here once GitHub renders it)

âš™ï¸ Project Workflow

This project follows a structured Fabric ETL pipeline, executed through a PySpark notebook and SQL queries:

1ï¸âƒ£ Extract â€” API Data Collection

File: notebook/anime_ingestion_cleaning.ipynb

âœ” Connects to Jikan REST API
âœ” Fetches anime metadata (title, score, genres, type, popularity, etc.)
âœ” Raw JSON is converted into a PySpark DataFrame

2ï¸âƒ£ Transform â€” Data Cleaning in PySpark

The PySpark notebook performs the following:

âœ” Extracts nested fields (genres, studios)
âœ” Handles missing values
âœ” Casts numeric fields
âœ” Renames and selects key analytics columns
âœ” Creates the final cleaned table: anime_cleaned

â¡ Output stored in Fabric Lakehouse (Delta Format)

3ï¸âƒ£ Load â€” Store & Query with Fabric SQL Endpoint

SQL files located in the sql/ folder include:

SQL File	Purpose
sql_top_anime.sql	Top 10 anime by score
sql_genre_count.sql	Count of anime per genre
sql_year_count.sql	Anime distribution by year

âœ” The Delta table is queryable inside Fabric using SQL Analytics Endpoint
âœ” Results feed into the Power BI dashboard

ğŸ–¥ï¸ Technologies & Tools Used
Tool / Tech	Purpose
Python (PySpark)	Data ingestion & transformation inside Fabric Notebook
Requests, Pandas	API calls & initial data handling
Microsoft Fabric Lakehouse	Storage of raw & cleaned Delta tables
Fabric SQL Endpoint	Running analytical SQL queries
Power BI Desktop	Interactive dashboard & visuals
Git & GitHub	Version control & project hosting
ğŸš€ How to Run This Project End-to-End
âœ… Prerequisites

Microsoft Fabric workspace

Python environment inside Fabric Notebook

Power BI Desktop installed

Git installed (optional, for local work)

ğŸ“Œ Step-by-Step Setup
1ï¸âƒ£ Clone the repository
git clone https://github.com/mishragourav0006-ops/anime_fabric_project.git
cd anime_fabric_project

2ï¸âƒ£ Open the PySpark notebook in Microsoft Fabric

Navigate to:

notebook/anime_ingestion_cleaning.ipynb


Run all cells to:

âœ” Fetch API data
âœ” Clean & transform it
âœ” Save the final Delta table into Lakehouse

3ï¸âƒ£ Run SQL Queries (Optional but Recommended)

Open each SQL file inside sql/:

-- Example: Top Anime
SELECT title, score
FROM anime_cleaned
ORDER BY score DESC
LIMIT 10;


These queries validate the dataset and feed into Power BI modeling.

4ï¸âƒ£ Open the Power BI Dashboard

Download the dataset via Fabric SQL endpoint
Import into Power BI â†’ build visuals OR open your saved .pbix file
View insights like:

Top-rated anime

Genre distribution

Score trends

Anime type breakdown

Popularity vs Score correlations

ğŸ“Š Dashboard Insights (Summary)

âœ” TV anime dominate the dataset compared to Movies
âœ” Action & Comedy are the most frequent genres
âœ” Rating trends show peak quality around 1999â€“2003
âœ” Some anime score high but are not extremely popular (and vice-versa)
âœ” Studios contribute differently to score and popularity metrics

ğŸ“ Project Structure
anime_fabric_project/
â”‚
â”œâ”€â”€ dashboard/
â”‚   â””â”€â”€ Anime_Dashboard.png
â”‚
â”œâ”€â”€ notebook/
â”‚   â””â”€â”€ anime_ingestion_cleaning.ipynb
â”‚
â”œâ”€â”€ sql/
â”‚   â”œâ”€â”€ sql_genre_count.sql
â”‚   â”œâ”€â”€ sql_top_anime.sql
â”‚   â””â”€â”€ sql_year_count.sql
â”‚
â””â”€â”€ README.md

ğŸ¯ Conclusion

This project demonstrates your ability to:

âœ” Build a professional ETL pipeline
âœ” Work with APIs & PySpark
âœ” Use Microsoft Fabric Lakehouse + SQL
âœ” Build real-world dashboards in Power BI
âœ” Structure a clean data engineering project for your portfolio
